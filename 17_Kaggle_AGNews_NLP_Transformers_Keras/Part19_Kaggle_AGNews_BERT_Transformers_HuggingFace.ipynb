{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f1bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "# pip install protobuf==4.21\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69477494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to be training pretty large models. In order not to face errors, we need\n",
    "# to set tensorflow option to grow GPU memory allocation when required.\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(physical_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa4d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "\n",
    "df_train=pd.read_csv('train_news.csv')\n",
    "df_test=pd.read_csv('test_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67857c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling data (changing labels 1..4 for 0..3 for a Dense layer to be within the requested range)\n",
    "\n",
    "df_train[['Class Index']]=df_train[['Class Index']].replace(to_replace=[1,2,3,4],value=[0,1,2,3])\n",
    "df_test[['Class Index']]=df_test[['Class Index']].replace(to_replace=[1,2,3,4],value=[0,1,2,3])\n",
    "# df_train[['Class Index']]=df_train[['Class Index']].replace(to_replace=[0,1,2,3],value=['World', 'Sports', 'Business', 'Sci/Tech'])\n",
    "# df_test[['Class Index']]=df_test[['Class Index']].replace(to_replace=[0,1,2,3],value=['World', 'Sports', 'Business', 'Sci/Tech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49610a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset = 120000\n",
      "Length of test dataset = 7600\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "\n",
    "print(f\"Length of train dataset = {len(df_train)}\")\n",
    "print(f\"Length of test dataset = {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc69d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Class Index  120000 non-null  int64 \n",
      " 1   Title        120000 non-null  object\n",
      " 2   Description  120000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7600 entries, 0 to 7599\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Class Index  7600 non-null   int64 \n",
      " 1   Title        7600 non-null   object\n",
      " 2   Description  7600 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 178.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info(), df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2a33fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            2  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            2  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22169761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            2                  Fears for T N pension after talks   \n",
       "1            3  The Race is On: Second Private Team Sets Launc...   \n",
       "2            3      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3            3      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4            3        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "\n",
       "                                         Description  \n",
       "0  Unions representing workers at Turner   Newall...  \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
       "2  AP - A company founded by a chemistry research...  \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...  \n",
       "4  AP - Southern California's smog-fighting agenc...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e323a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a combined column of Titles and Descriptions\n",
    "\n",
    "df_train['Combined']=df_train['Title']+' '+df_train['Description']\n",
    "df_test['Combined']=df_test['Title']+' '+df_test['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c4699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model from Internet repository using model name. \n",
    "# Use this if you are running from your own copy of the notebooks\n",
    "bert_model = 'bert-base-uncased' \n",
    "\n",
    "# To load the model from the directory on disk. Use this for Microsoft Learn module, because we have\n",
    "# prepared all required files for you.\n",
    "#bert_model = './bert'\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(bert_model)\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a60ff9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2292, 1005, 1055, 4638, 2129, 2009, 2573, 102]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Let's check how it works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f7bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 101, 7592, 1010, 2088,  102]])>, 'token_type_ids': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[1, 1, 1, 1, 1]])>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['Hello, world'],return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fb081e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 10069, 2005, 1056, 1050, 11550, 2044, 7566, 9209, 5052, 3667, 2012, 6769, 2047, 8095, 2360, 2027, 2024, 1005, 9364, 1005, 2044, 7566, 2007, 16654, 6687, 3813, 2976, 9587, 24848, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking an output format - it's a dictionary with k:v pairs\n",
    "\n",
    "tokenizer(df_test['Combined'][0],padding='max_length',max_length=MAX_SEQ_LEN,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feff48bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [101, 2813, 2358, 1012, 6468, 15020, 2067, 204...\n",
       "1         [101, 18431, 2571, 3504, 2646, 3293, 13395, 10...\n",
       "2         [101, 3514, 1998, 4610, 6112, 15768, 1005, 176...\n",
       "3         [101, 5712, 9190, 2015, 3514, 14338, 2013, 236...\n",
       "4         [101, 3514, 7597, 2061, 2906, 2000, 2035, 1011...\n",
       "                                ...                        \n",
       "119995    [101, 4501, 1005, 1055, 14163, 7377, 11335, 25...\n",
       "119996    [101, 9278, 11610, 6608, 1037, 2327, 1011, 111...\n",
       "119997    [101, 7842, 8193, 2025, 2183, 2000, 13600, 266...\n",
       "119998    [101, 2651, 1005, 1055, 5088, 2399, 6278, 2012...\n",
       "119999    [101, 16996, 2131, 5708, 2013, 9680, 6591, 950...\n",
       "Name: Tokens, Length: 120000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When training the model, we need to provide tokenized sequence as input for train and test data\n",
    "\n",
    "df_train['Tokens']=[\n",
    "    tokenizer(x,\n",
    "    padding='max_length',max_length=MAX_SEQ_LEN,truncation=True)['input_ids']\n",
    "    for x in df_train['Combined']\n",
    "]\n",
    "df_train['Tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc75fc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 10069, 2005, 1056, 1050, 11550, 2044, 75...\n",
       "1       [101, 1996, 2679, 2003, 2006, 1024, 2117, 2797...\n",
       "2       [101, 18712, 1012, 2194, 5222, 3946, 2000, 281...\n",
       "3       [101, 17547, 3131, 7126, 19939, 3748, 26332, 1...\n",
       "4       [101, 10250, 10128, 1012, 8704, 2000, 5787, 38...\n",
       "                              ...                        \n",
       "7595    [101, 2105, 1996, 2088, 5969, 4883, 4018, 1348...\n",
       "7596    [101, 11675, 2003, 3561, 2007, 12223, 2007, 19...\n",
       "7597    [101, 10337, 3727, 8618, 2066, 5074, 27277, 21...\n",
       "7598    [101, 1019, 1997, 27641, 5022, 1999, 5264, 220...\n",
       "7599    [101, 1041, 15907, 4152, 2046, 12635, 2015, 10...\n",
       "Name: Tokens, Length: 7600, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When training the model, we need to provide tokenized sequence as input for train and test data\n",
    "\n",
    "df_test['Tokens']=[\n",
    "    tokenizer(x,\n",
    "    padding='max_length',max_length=MAX_SEQ_LEN,truncation=True)['input_ids']\n",
    "    for x in df_test['Combined']\n",
    "]\n",
    "df_test['Tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c572e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Tokens to tensors\n",
    "\n",
    "x_test=[tf.convert_to_tensor(x, dtype=tf.int32) for x in df_test['Tokens']]\n",
    "x_train=[tf.convert_to_tensor(x, dtype=tf.int32) for x in df_train['Tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf78e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  3076      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109485316 (417.65 MB)\n",
      "Trainable params: 109485316 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The model contains almost 110 million parameters! \n",
    "\n",
    "model = transformers.TFBertForSequenceClassification.from_pretrained(bert_model,num_labels=4,output_attentions=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f08e881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  3076      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109485316 (417.65 MB)\n",
      "Trainable params: 3076 (12.02 KB)\n",
      "Non-trainable params: 109482240 (417.64 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Since we want simple classification task on relatively small dataset, \n",
    "# we do not want to train the BERT base layer\n",
    "\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec12e8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 332s 10s/step - loss: 8.8484 - acc: 0.2422 - val_loss: 11.9497 - val_acc: 0.2344\n"
     ]
    }
   ],
   "source": [
    "# Initiating the model \n",
    "\n",
    "model.compile('adam','sparse_categorical_crossentropy',['acc'])\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "history=model.fit(tf.cast(x_train, tf.int32), df_train['Class Index'].values,\n",
    "          validation_data=[tf.cast(x_test, tf.int32), df_test['Class Index'].values],\n",
    "          batch_size=32,steps_per_epoch=32,validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c68a5799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [8.8484468460083],\n",
       " 'acc': [0.2421875],\n",
       " 'val_loss': [11.94973373413086],\n",
       " 'val_acc': [0.234375]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model is very large and needs more training to improve the results \n",
    "# (which are likely to be the best comparing to RNN and self-made Transformers I used in the previous cases)\n",
    "\n",
    "history.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
