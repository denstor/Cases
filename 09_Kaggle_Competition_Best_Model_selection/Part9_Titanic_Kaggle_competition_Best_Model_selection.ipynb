{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "efc17cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libs\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "69d028b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "215ebd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "f12f5762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.39755838641189,\n",
       " 30.089726775956283,\n",
       " 22.62,\n",
       " 13.916666666666666,\n",
       " 7.055555555555555,\n",
       " 10.2)"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special treatment of nans for Age due to dependence upon SibSp\n",
    "df['Age'].replace(np.nan, -1,inplace=True)\n",
    "ssm_0=df.Age[(df.Age!=-1)&(df.SibSp==0)].mean()\n",
    "ssm_1=df.Age[(df.Age!=-1)&(df.SibSp==1)].mean()\n",
    "ssm_2=df.Age[(df.Age!=-1)&(df.SibSp==2)].mean()\n",
    "ssm_3=df.Age[(df.Age!=-1)&(df.SibSp==3)].mean()\n",
    "ssm_4=df.Age[(df.Age!=-1)&(df.SibSp==4)].mean()\n",
    "ssm_5=df.Age[(df.Age!=-1)&(df.SibSp==5)].mean()\n",
    "ssm_0,ssm_1,ssm_2,ssm_3,ssm_4,ssm_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "380110c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_10288\\3929848419.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Age[(df.Age==-1)&(df.SibSp==0)]=ssm_0\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_10288\\3929848419.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Age[(df.Age==-1)&(df.SibSp==1)]=ssm_1\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_10288\\3929848419.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Age[(df.Age==-1)&(df.SibSp==2)]=ssm_2\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_10288\\3929848419.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Age[(df.Age==-1)&(df.SibSp==3)]=ssm_3\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_10288\\3929848419.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Age[(df.Age==-1)&(df.SibSp==4)]=ssm_4\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_10288\\3929848419.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Age[(df.Age==-1)&(df.SibSp==5)]=ssm_5\n"
     ]
    }
   ],
   "source": [
    "df.Age[(df.Age==-1)&(df.SibSp==0)]=ssm_0\n",
    "df.Age[(df.Age==-1)&(df.SibSp==1)]=ssm_1\n",
    "df.Age[(df.Age==-1)&(df.SibSp==2)]=ssm_2\n",
    "df.Age[(df.Age==-1)&(df.SibSp==3)]=ssm_3\n",
    "df.Age[(df.Age==-1)&(df.SibSp==4)]=ssm_4\n",
    "df.Age[(df.Age==-1)&(df.SibSp==5)]=ssm_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "ffa764cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    int64  \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 55.8 KB\n"
     ]
    }
   ],
   "source": [
    "# deleting non-informative columns, coding categorical columns, fillna\n",
    "df=df.drop(columns=['PassengerId','Name','Cabin','Ticket'],axis=1)\n",
    "df.Sex.replace(to_replace=['male','female'],value=[0,1], inplace=True)\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].value_counts().index[0])\n",
    "df.Embarked.replace(to_replace=['S','C','Q'],value=[0,1,2], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "c8efca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturbation of the dataset before modelling\n",
    "dfr=pd.DataFrame(np.random.permutation(df.values),columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "141063fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining x and y\n",
    "x=dfr.drop(columns=['Survived'],axis=1)\n",
    "y=dfr[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "d9f8dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "1dd39788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data for x, train and test (keeping logics of fitting and transforming)\n",
    "scaler=StandardScaler()\n",
    "x_all=scaler.fit(x)\n",
    "xx=x_all.transform(x)\n",
    "X_tr=scaler.fit(X_train)\n",
    "X_tr_sc=X_tr.transform(X_train)\n",
    "X_t_sc=X_tr.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "01736146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.80 (0.01)\n",
      "LDA: 0.79 (0.01)\n",
      "KNN: 0.80 (0.03)\n",
      "NB: 0.79 (0.02)\n",
      "SVM: 0.82 (0.02)\n",
      "CART: 0.78 (0.01)\n",
      "GBC: 0.82 (0.02)\n",
      "XGB: 0.81 (0.02)\n"
     ]
    }
   ],
   "source": [
    "# since we work with the classification problem, the classifiers were selected for modelling\n",
    "# set of different models to choose the best ones for further experiments\n",
    "# I've chosen 4 models (SVM, GBC, XGB and the simplest one - LR)\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('GBC', GradientBoostingClassifier()))\n",
    "models.append(('XGB', xgb.XGBClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, xx, np.ravel(y), cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %.2f (%.2f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "e5455038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'n_estimators': 250, 'max_depth': 2, 'colsample_bytree': 0.3}\n",
      "Best accuracy:  0.8170547988199107\n"
     ]
    }
   ],
   "source": [
    "# XGB Hyperparater tuning by utilizing RandomizedSearchCV (a faster option)\n",
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "gbm = xgb.XGBClassifier()\n",
    "gbm_param_grid_RG = {\n",
    "    'colsample_bytree': [0.3, 0.7, 1.0],\n",
    "    'n_estimators': [150,200,250,300],\n",
    "    'max_depth': range(2, 11)}\n",
    "randomized_gbm = RandomizedSearchCV(param_distributions=gbm_param_grid_RG, estimator=gbm, scoring=\"accuracy\", n_iter=10, cv=5, verbose=1)\n",
    "randomized_gbm.fit(x, y)\n",
    "print(\"Best parameters found: \", randomized_gbm.best_params_)\n",
    "print(\"Best accuracy: \", randomized_gbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "d9c2e0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      "0.81\n",
      "________________________________________________________\n",
      "confusion_matrix\n",
      "[[105  13]\n",
      " [ 21  40]]\n",
      "________________________________________________________\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86       118\n",
      "         1.0       0.75      0.66      0.70        61\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.79      0.77      0.78       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB - print accuracy, confusion matrix & classification report for test data\n",
    "xgb_params=randomized_gbm.best_params_\n",
    "xgb_opt=xgb.XGBClassifier(**xgb_params)\n",
    "xgb_opt.fit(X_train,y_train)\n",
    "predictions0=xgb_opt.predict(X_test)\n",
    "\n",
    "print(\"accuracy_score\")\n",
    "print('%.2f' % accuracy_score(np.ravel(y_test), predictions0))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"confusion_matrix\")\n",
    "print(confusion_matrix(np.ravel(y_test), predictions0))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"classification_report\")\n",
    "print(classification_report(np.ravel(y_test), predictions0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "dee04914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 'scale', 'C': 1.0}\n",
      "Lowest score:  0.8248948590797817\n"
     ]
    }
   ],
   "source": [
    "# CVM Hyperparater tuning by utilizing RandomizedSearchCV \n",
    "svm=SVC(gamma='auto')\n",
    "svm_param_grid = {'C': [50, 10, 1.0, 0.1, 0.01], \n",
    "              'gamma': ['scale'],\n",
    "              'kernel': ['linear','poly', 'rbf', 'sigmoid']} \n",
    "randomized_svm = RandomizedSearchCV(param_distributions=svm_param_grid, estimator=svm, scoring=\"accuracy\", n_iter=10, cv=5, verbose=1)\n",
    "randomized_svm.fit(xx,np.ravel(y))\n",
    "print(\"Best parameters found: \", randomized_svm.best_params_)\n",
    "print(\"Lowest score: \", randomized_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "d72a118f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best parameters after tuning\n",
    "svm_pars=grid1.best_params_\n",
    "svm_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "eaeed39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model with the optimal parameters\n",
    "svm_opt=SVC(**svm_pars)\n",
    "svm_opt.fit(X_tr_sc, np.ravel(y_train))\n",
    "predictions1=svm_opt.predict(X_t_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "fb3c3012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      "0.84\n",
      "________________________________________________________\n",
      "confusion_matrix\n",
      "[[112   6]\n",
      " [ 22  39]]\n",
      "________________________________________________________\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.89       118\n",
      "         1.0       0.87      0.64      0.74        61\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.85      0.79      0.81       179\n",
      "weighted avg       0.85      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print accuracy, confusion matrix & classification report for test data\n",
    "print(\"accuracy_score\")\n",
    "print('%.2f' % accuracy_score(np.ravel(y_test), predictions1))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"confusion_matrix\")\n",
    "print(confusion_matrix(np.ravel(y_test), predictions1))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"classification_report\")\n",
    "print(classification_report(np.ravel(y_test), predictions1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "ee857289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.1}\n",
      "Best score:  0.8035465444730401\n"
     ]
    }
   ],
   "source": [
    "# LGR Hyperparater tuning by utilizing RandomizedSearchCV \n",
    "lgr=LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "lgr_param_grid = {'solver' : ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "              'penalty' : ['l2'],\n",
    "              'C' : [100, 10, 1.0, 0.1, 0.01]} \n",
    "randomized_lgr = RandomizedSearchCV(param_distributions=lgr_param_grid, estimator=lgr, scoring=\"accuracy\", n_iter=10, cv=5, verbose=1)\n",
    "randomized_lgr.fit(xx,np.ravel(y))\n",
    "print(\"Best parameters found: \", randomized_lgr.best_params_)\n",
    "print(\"Best score: \", randomized_lgr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "72077257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model with the optimal parameters\n",
    "lgr_opt=LogisticRegression(C=0.1, solver='newton-cg',penalty='l2')\n",
    "lgr_opt.fit(X_tr_sc, np.ravel(y_train))\n",
    "predictions2=lgr_opt.predict(X_t_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "b898f445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      "0.83\n",
      "________________________________________________________\n",
      "confusion_matrix\n",
      "[[102  16]\n",
      " [ 15  46]]\n",
      "________________________________________________________\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.86      0.87       118\n",
      "         1.0       0.74      0.75      0.75        61\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.81      0.81      0.81       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print accuracy, confusion matrix & classification report for test data\n",
    "print(\"accuracy_score\")\n",
    "print('%.2f' % accuracy_score(np.ravel(y_test), predictions2))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"confusion_matrix\")\n",
    "print(confusion_matrix(np.ravel(y_test), predictions2))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"classification_report\")\n",
    "print(classification_report(np.ravel(y_test), predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "ec579000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random grid:  {'n_estimators': [5, 20, 50, 100, 150, 200, 300], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120], 'max_leaf_nodes': [2, 5, 10, 20, 50, 100], 'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B5DD506DA0>} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGBC Hyperparater tuning by utilizing RandomizedSearchCV \n",
    "from scipy.stats import loguniform\n",
    "n_estimators = [5,20,50,100,150,200,300] # number of trees in the random forest\n",
    "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
    "max_leaf_nodes=[2, 5, 10, 20, 50, 100]\n",
    "\n",
    "gbc_random_grid = {'n_estimators': n_estimators,\n",
    "'max_depth': max_depth,\n",
    "'max_leaf_nodes':max_leaf_nodes,\n",
    "'learning_rate': loguniform(0.01, 1)}\n",
    "\n",
    "print ('Random grid: ', gbc_random_grid, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "90f62a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'learning_rate': 0.19687245414460147, 'max_depth': 50, 'max_leaf_nodes': 20, 'n_estimators': 5}\n",
      "Best score:  0.8383717280773334\n"
     ]
    }
   ],
   "source": [
    "# retrieving the best score and the optimal parameters\n",
    "gbc=GradientBoostingClassifier()\n",
    "gbc_random = RandomizedSearchCV(estimator = gbc,param_distributions = gbc_random_grid,\n",
    "               n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1, scoring=\"accuracy\")\n",
    "gbc_random.fit(x, np.ravel(y))\n",
    "print(\"Best parameters found: \", gbc_random.best_params_)\n",
    "print(\"Best score: \", gbc_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "ac51b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model with the optimal parameters\n",
    "gbc_opt_params=gbc_random.best_params_\n",
    "gbc_opt = GradientBoostingClassifier(**gbc_opt_params)\n",
    "gbc_opt.fit(X_train,np.ravel(y_train))\n",
    "predictions3=gbc_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "d0f137ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      "0.81\n",
      "________________________________________________________\n",
      "confusion_matrix\n",
      "[[103  15]\n",
      " [ 19  42]]\n",
      "________________________________________________________\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.87      0.86       118\n",
      "         1.0       0.74      0.69      0.71        61\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.79      0.78      0.79       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print accuracy, confusion matrix & classification report for test data\n",
    "print(\"accuracy_score\")\n",
    "print('%.2f' % accuracy_score(np.ravel(y_test), predictions3))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"confusion_matrix\")\n",
    "print(confusion_matrix(np.ravel(y_test), predictions3))\n",
    "print(\"________________________________________________________\")\n",
    "print(\"classification_report\")\n",
    "print(classification_report(np.ravel(y_test), predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "d6133d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM, GBC and XGB - the best set of models to achieve the highest score for the testing dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
